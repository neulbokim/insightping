"""
ë¯¼ê°ë„ ë¶„ì„ (Sensitivity Analysis)
STO ë„ì… ì‹œ ë¦¬ìŠ¤í¬ì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ì£¼ìš” ë³€ìˆ˜ íŒŒì•…

ë°©ë²•ë¡ :
1. One-at-a-Time (OAT) ë¯¼ê°ë„ ë¶„ì„
2. Tornado ë‹¤ì´ì–´ê·¸ë¨ (ë³€ìˆ˜ë³„ ì˜í–¥ë„)
3. 2D ë¯¼ê°ë„ ë§µ (2ê°œ ë³€ìˆ˜ ë™ì‹œ ë³€í™”)
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from pf_simulation_v2 import SimulationParams, ImprovedPFSimulation
from pf_analysis_v2 import ImprovedRiskAnalyzer
import time

# í•œê¸€ í°íŠ¸ ì„¤ì •
import matplotlib.font_manager as fm
font_list = [f.name for f in fm.fontManager.ttflist]
if 'Malgun Gothic' in font_list:
    plt.rcParams['font.family'] = 'Malgun Gothic'
elif 'NanumGothic' in font_list:
    plt.rcParams['font.family'] = 'NanumGothic'
elif 'AppleGothic' in font_list:
    plt.rcParams['font.family'] = 'AppleGothic'
else:
    plt.rcParams['font.family'] = 'DejaVu Sans'
plt.rcParams['axes.unicode_minus'] = False


# ===== ê¸°ì¤€ ì‹œë‚˜ë¦¬ì˜¤ (Baseline) =====
BASELINE_PARAMS = {
    'n_simulations': 5000,
    'n_projects': 100,
    'T': 16,
    'sto_ratio': 0.28,  # STO 28%
    'use_logistic_sales': False,
    'mu_sales_base': 0.00,
    'sigma_sales': 0.25,
    'recovery_rate_base': 0.25,
    'collateral_ratio': 0.30,
    'rho_base': 0.30,
    'fire_sale_base': 0.50,
}


# ===== ë¯¼ê°ë„ ë¶„ì„ ë³€ìˆ˜ ë²”ìœ„ =====
SENSITIVITY_VARIABLES = {
    'sto_ratio': {
        'label': 'STO ë¹„ìœ¨ (%)',
        'baseline': 0.28,
        'range': [0.10, 0.15, 0.20, 0.28, 0.35, 0.40, 0.45, 0.50],
        'unit': '%',
        'format': lambda x: f'{x*100:.0f}%'
    },
    'mu_sales_base': {
        'label': 'ë¶„ì–‘ë¥  ì„±ì¥ë¥  (%/ë¶„ê¸°)',
        'baseline': 0.00,
        'range': [-0.05, -0.03, -0.01, 0.00, 0.01, 0.03, 0.05],
        'unit': '%',
        'format': lambda x: f'{x*100:+.1f}%'
    },
    'sigma_sales': {
        'label': 'ë¶„ì–‘ë¥  ë³€ë™ì„±',
        'baseline': 0.25,
        'range': [0.10, 0.15, 0.20, 0.25, 0.30, 0.35, 0.40],
        'unit': '',
        'format': lambda x: f'{x:.2f}'
    },
    'recovery_rate_base': {
        'label': 'ê¸°ë³¸ íšŒìˆ˜ìœ¨ (%)',
        'baseline': 0.25,
        'range': [0.10, 0.15, 0.20, 0.25, 0.30, 0.35, 0.40],
        'unit': '%',
        'format': lambda x: f'{x*100:.0f}%'
    },
    'collateral_ratio': {
        'label': 'ë‹´ë³´ ë¹„ìœ¨ (%)',
        'baseline': 0.30,
        'range': [0.00, 0.10, 0.20, 0.30, 0.40, 0.50, 0.60],
        'unit': '%',
        'format': lambda x: f'{x*100:.0f}%'
    },
    'rho_base': {
        'label': 'ê¸°ë³¸ ìƒê´€ê³„ìˆ˜',
        'baseline': 0.30,
        'range': [0.00, 0.10, 0.20, 0.30, 0.40, 0.50, 0.60],
        'unit': '',
        'format': lambda x: f'{x:.2f}'
    },
    'fire_sale_base': {
        'label': 'í™”ê¸‰ë§¤ê° í• ì¸ìœ¨ (%)',
        'baseline': 0.50,
        'range': [0.30, 0.40, 0.50, 0.60, 0.70, 0.80],
        'unit': '%',
        'format': lambda x: f'{x*100:.0f}%'
    },
}


def run_single_scenario(param_overrides):
    """ë‹¨ì¼ ì‹œë‚˜ë¦¬ì˜¤ ì‹¤í–‰"""
    params_dict = BASELINE_PARAMS.copy()
    params_dict.update(param_overrides)
    
    params = SimulationParams(**params_dict)
    sim = ImprovedPFSimulation(params, use_sto=True)
    results = sim.run_simulation()
    
    analyzer = ImprovedRiskAnalyzer(results, params)
    metrics = analyzer.calculate_all_metrics()
    
    # í™•ì¥ ì‹œìŠ¤í…œ VaR ê³„ì‚°
    financial_var = metrics['VaR_95']
    retail_var = metrics['retail_VaR_95']
    extended_var = financial_var + retail_var
    system_change = retail_var
    
    return {
        'Financial_VaR95': financial_var,
        'Retail_VaR95': retail_var,
        'Extended_VaR95': extended_var,
        'System_Risk_Change': system_change,
        'Retail_Loss_Rate_VaR95': metrics['retail_loss_rate_VaR95'],
        'Retail_Loss_Rate_ES95': metrics['retail_loss_rate_ES95'],
    }


def run_oat_sensitivity_analysis():
    """One-at-a-Time ë¯¼ê°ë„ ë¶„ì„"""
    print("="*80)
    print("One-at-a-Time (OAT) ë¯¼ê°ë„ ë¶„ì„ ì‹œì‘")
    print("="*80)
    
    results = {}
    
    # ê¸°ì¤€ ì‹œë‚˜ë¦¬ì˜¤ ì‹¤í–‰
    print("\n[Baseline] ê¸°ì¤€ ì‹œë‚˜ë¦¬ì˜¤ ì‹¤í–‰ ì¤‘...")
    baseline_results = run_single_scenario({})
    
    print(f"  Financial VaR95: {baseline_results['Financial_VaR95']:,.0f}ì–µ")
    print(f"  Retail VaR95: {baseline_results['Retail_VaR95']:,.0f}ì–µ")
    print(f"  Extended VaR95: {baseline_results['Extended_VaR95']:,.0f}ì–µ")
    
    results['baseline'] = baseline_results
    
    # ê° ë³€ìˆ˜ë³„ ë¯¼ê°ë„ ë¶„ì„
    for var_name, var_info in SENSITIVITY_VARIABLES.items():
        print(f"\n[{var_info['label']}] ë¯¼ê°ë„ ë¶„ì„ ì¤‘...")
        
        var_results = []
        
        for value in var_info['range']:
            print(f"  {var_info['format'](value)} ", end='', flush=True)
            
            scenario_results = run_single_scenario({var_name: value})
            scenario_results['value'] = value
            var_results.append(scenario_results)
            
            print("âœ“", end='', flush=True)
        
        print()  # ì¤„ë°”ê¿ˆ
        results[var_name] = var_results
    
    print("\n" + "="*80)
    print("âœ… OAT ë¯¼ê°ë„ ë¶„ì„ ì™„ë£Œ")
    print("="*80)
    
    return results, baseline_results


def calculate_sensitivity_metrics(results, baseline):
    """ë¯¼ê°ë„ ì§€í‘œ ê³„ì‚°"""
    sensitivity_metrics = []
    
    for var_name, var_results in results.items():
        if var_name == 'baseline':
            continue
        
        var_info = SENSITIVITY_VARIABLES[var_name]
        
        # ê° ì¶œë ¥ ì§€í‘œë³„ ë¯¼ê°ë„
        for output_metric in ['Financial_VaR95', 'Retail_VaR95', 'Extended_VaR95', 'System_Risk_Change']:
            values = [r[output_metric] for r in var_results]
            
            # ë¯¼ê°ë„ = (Max - Min) / Baseline
            sensitivity = (max(values) - min(values)) / baseline[output_metric] * 100
            
            # ê¸°ìš¸ê¸° (ì„ í˜• ê·¼ì‚¬)
            x = var_info['range']
            y = values
            slope = np.polyfit(x, y, 1)[0]
            
            sensitivity_metrics.append({
                'Variable': var_info['label'],
                'Output_Metric': output_metric,
                'Sensitivity_Pct': sensitivity,
                'Slope': slope,
                'Min_Value': min(values),
                'Max_Value': max(values),
                'Range': max(values) - min(values),
            })
    
    df = pd.DataFrame(sensitivity_metrics)
    return df


def create_tornado_diagram(sensitivity_df, baseline):
    """Tornado ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±"""
    
    fig, axes = plt.subplots(2, 2, figsize=(22, 18))
    fig.suptitle('ë¯¼ê°ë„ ë¶„ì„: Tornado ë‹¤ì´ì–´ê·¸ë¨ (STO 28% ê¸°ì¤€)\në³€ìˆ˜ë³„ ì˜í–¥ë ¥ ìˆœìœ„', 
                 fontsize=18, fontweight='bold', y=0.995)
    
    output_metrics = ['Financial_VaR95', 'Retail_VaR95', 'Extended_VaR95', 'System_Risk_Change']
    metric_labels = ['ê¸ˆìœµê¸°ê´€ VaR95', 'ê°œì¸ íˆ¬ìì VaR95', 'í™•ì¥ ì‹œìŠ¤í…œ VaR95', 'ì‹œìŠ¤í…œ ë¦¬ìŠ¤í¬ ì¦ê°€']
    
    for idx, (metric, label) in enumerate(zip(output_metrics, metric_labels)):
        ax = axes[idx // 2, idx % 2]
        
        # í•´ë‹¹ ì§€í‘œì— ëŒ€í•œ ë¯¼ê°ë„ í•„í„°ë§
        metric_data = sensitivity_df[sensitivity_df['Output_Metric'] == metric].copy()
        metric_data = metric_data.sort_values('Sensitivity_Pct', ascending=True)
        
        # Tornado ì°¨íŠ¸
        y_pos = np.arange(len(metric_data))
        
        # ìµœì†Œê°’ê³¼ ìµœëŒ€ê°’ì˜ ë³€í™”ëŸ‰
        baseline_value = baseline[metric]
        low_change = (metric_data['Min_Value'] - baseline_value) / baseline_value * 100
        high_change = (metric_data['Max_Value'] - baseline_value) / baseline_value * 100
        
        # ë§‰ëŒ€ ê·¸ë˜í”„
        bars_high = ax.barh(y_pos, high_change, left=0, color='lightcoral', 
                           edgecolor='black', linewidth=1.5, label='ì¦ê°€ (Max)', alpha=0.8)
        bars_low = ax.barh(y_pos, low_change, left=0, color='lightblue', 
                          edgecolor='black', linewidth=1.5, label='ê°ì†Œ (Min)', alpha=0.8)
        
        # ê¸°ì¤€ì„ 
        ax.axvline(0, color='black', linewidth=2.5, linestyle='--', alpha=0.8)
        
        # ë ˆì´ë¸” (ìˆœìœ„ ì¶”ê°€)
        labels_with_rank = [f'{i+1}. {var}' for i, var in enumerate(metric_data['Variable'])]
        ax.set_yticks(y_pos)
        ax.set_yticklabels(labels_with_rank, fontsize=11)
        ax.set_xlabel('ê¸°ì¤€ ëŒ€ë¹„ ë³€í™”ìœ¨ (%)', fontsize=13, fontweight='bold')
        ax.set_title(f'{label}\n(ê¸°ì¤€: {baseline_value:,.0f}ì–µ)', 
                     fontsize=14, fontweight='bold', pad=15)
        ax.legend(fontsize=11, loc='best', framealpha=0.9)
        ax.grid(True, alpha=0.3, axis='x')
        
        # ê°’ í‘œì‹œ (ë” í° í°íŠ¸)
        for i, (low, high) in enumerate(zip(low_change, high_change)):
            if abs(low) > 3:  # 3% ì´ìƒë§Œ í‘œì‹œ
                ax.text(low - 2, i, f'{low:.1f}%', 
                       ha='right', va='center', fontsize=10, fontweight='bold',
                       bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))
            if abs(high) > 3:
                ax.text(high + 2, i, f'{high:.1f}%', 
                       ha='left', va='center', fontsize=10, fontweight='bold',
                       bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))
        
        # ë²”ìœ„ í‘œì‹œ
        ax.set_xlim(min(low_change.min(), high_change.min()) * 1.2,
                   max(low_change.max(), high_change.max()) * 1.2)
    
    plt.tight_layout()
    plt.savefig('sensitivity_tornado.png', dpi=150, bbox_inches='tight')
    print("\nâœ… Tornado ë‹¤ì´ì–´ê·¸ë¨ ì €ì¥: sensitivity_tornado.png")


def create_sensitivity_curves(results, baseline):
    """ë¯¼ê°ë„ ê³¡ì„  ê·¸ë˜í”„"""
    
    fig = plt.figure(figsize=(24, 20))
    gs = fig.add_gridspec(4, 4, hspace=0.35, wspace=0.3)
    
    output_metrics = ['Financial_VaR95', 'Retail_VaR95', 'Extended_VaR95', 'System_Risk_Change']
    metric_labels = ['ê¸ˆìœµê¸°ê´€ VaR95 (ì–µì›)', 'ê°œì¸ íˆ¬ìì VaR95 (ì–µì›)', 
                     'í™•ì¥ ì‹œìŠ¤í…œ VaR95 (ì–µì›)', 'ì‹œìŠ¤í…œ ë¦¬ìŠ¤í¬ ì¦ê°€ (ì–µì›)']
    
    colors = plt.cm.tab10(np.linspace(0, 1, 7))
    
    for row, (metric, label) in enumerate(zip(output_metrics, metric_labels)):
        
        for col, (var_name, var_info) in enumerate(SENSITIVITY_VARIABLES.items()):
            if col >= 4:  # 4ì—´ê¹Œì§€ë§Œ
                continue
            
            ax = fig.add_subplot(gs[row, col])
            
            var_results = results[var_name]
            x_values = [r['value'] for r in var_results]
            y_values = [r[metric] for r in var_results]
            
            # ê¸°ì¤€ì„ 
            baseline_x = var_info['baseline']
            baseline_y = baseline[metric]
            
            # ê³¡ì„ 
            ax.plot(x_values, y_values, 'o-', linewidth=2.5, 
                   markersize=6, color=colors[col], label=var_info['label'])
            
            # ê¸°ì¤€ì  ê°•ì¡°
            ax.plot(baseline_x, baseline_y, 'r*', markersize=15, 
                   label='Baseline', zorder=5)
            
            # ìŠ¤íƒ€ì¼
            ax.set_xlabel(var_info['label'], fontsize=11)
            if col == 0:
                ax.set_ylabel(label, fontsize=11)
            ax.grid(True, alpha=0.3)
            ax.legend(fontsize=9, loc='best')
            
            # Xì¶• í¬ë§·
            ax.set_xticks(x_values[::2])  # ê²©ìë¡œ í‘œì‹œ
            ax.set_xticklabels([var_info['format'](v) for v in x_values[::2]], 
                              rotation=45, fontsize=9)
    
    # ë‚˜ë¨¸ì§€ 3ê°œ ë³€ìˆ˜ (ë‘ ë²ˆì§¸ í–‰)
    remaining_vars = list(SENSITIVITY_VARIABLES.items())[4:]
    for col, (var_name, var_info) in enumerate(remaining_vars):
        
        for row, (metric, label) in enumerate(zip(output_metrics, metric_labels)):
            
            ax = fig.add_subplot(gs[row, col])
            
            var_results = results[var_name]
            x_values = [r['value'] for r in var_results]
            y_values = [r[metric] for r in var_results]
            
            baseline_x = var_info['baseline']
            baseline_y = baseline[metric]
            
            ax.plot(x_values, y_values, 'o-', linewidth=2.5, 
                   markersize=6, color=colors[col+4], label=var_info['label'])
            ax.plot(baseline_x, baseline_y, 'r*', markersize=15, 
                   label='Baseline', zorder=5)
            
            ax.set_xlabel(var_info['label'], fontsize=11)
            ax.grid(True, alpha=0.3)
            ax.legend(fontsize=9, loc='best')
            
            ax.set_xticks(x_values[::2])
            ax.set_xticklabels([var_info['format'](v) for v in x_values[::2]], 
                              rotation=45, fontsize=9)
    
    fig.suptitle('ë¯¼ê°ë„ ë¶„ì„: ë³€ìˆ˜ë³„ ì˜í–¥ ê³¡ì„  (STO 28% ê¸°ì¤€)', 
                 fontsize=18, fontweight='bold', y=0.998)
    
    plt.savefig('sensitivity_curves.png', dpi=150, bbox_inches='tight')
    print("âœ… ë¯¼ê°ë„ ê³¡ì„  ì €ì¥: sensitivity_curves.png")


def export_sensitivity_to_excel(sensitivity_df, results, baseline):
    """Excelë¡œ ê²°ê³¼ ë‚´ë³´ë‚´ê¸°"""
    
    with pd.ExcelWriter('sensitivity_analysis_results.xlsx', engine='openpyxl') as writer:
        
        # Sheet 1: Summary
        summary = sensitivity_df.pivot_table(
            index='Variable', 
            columns='Output_Metric', 
            values='Sensitivity_Pct'
        )
        summary.to_excel(writer, sheet_name='Sensitivity_Summary')
        
        # Sheet 2: Detailed Results
        sensitivity_df.to_excel(writer, sheet_name='Detailed_Metrics', index=False)
        
        # Sheet 3-9: ê° ë³€ìˆ˜ë³„ ìƒì„¸ ê²°ê³¼
        for var_name, var_results in results.items():
            if var_name == 'baseline':
                continue
            
            var_df = pd.DataFrame(var_results)
            var_df.to_excel(writer, sheet_name=var_name[:31], index=False)
    
    print("âœ… Excel íŒŒì¼ ì €ì¥: sensitivity_analysis_results.xlsx")


def print_sensitivity_insights(sensitivity_df):
    """í•µì‹¬ ì¸ì‚¬ì´íŠ¸ ì¶œë ¥"""
    
    print("\n" + "="*80)
    print("ğŸ“Š ë¯¼ê°ë„ ë¶„ì„ í•µì‹¬ ì¸ì‚¬ì´íŠ¸ (Tornado Diagram ê¸°ë°˜)")
    print("="*80)
    
    for metric, label in [('Financial_VaR95', 'ê¸ˆìœµê¸°ê´€ VaR95'),
                          ('Retail_VaR95', 'ê°œì¸ íˆ¬ìì VaR95'),
                          ('Extended_VaR95', 'í™•ì¥ ì‹œìŠ¤í…œ VaR95'),
                          ('System_Risk_Change', 'ì‹œìŠ¤í…œ ë¦¬ìŠ¤í¬ ì¦ê°€')]:
        
        metric_data = sensitivity_df[sensitivity_df['Output_Metric'] == metric]
        top3 = metric_data.nlargest(3, 'Sensitivity_Pct')
        
        print(f"\n{'='*80}")
        print(f"ğŸ¯ {label}ì— ê°€ì¥ í° ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ë³€ìˆ˜ (Top 3):")
        print(f"{'='*80}")
        
        for i, row in enumerate(top3.itertuples(), 1):
            rank_emoji = ['ğŸ¥‡', 'ğŸ¥ˆ', 'ğŸ¥‰'][i-1]
            print(f"\n{rank_emoji} {i}ìœ„: {row.Variable}")
            print(f"   ë¯¼ê°ë„: Â±{row.Sensitivity_Pct:.1f}% (ì˜í–¥ë ¥ ì§€ìˆ˜)")
            print(f"   ë³€ë™ ë²”ìœ„: {row.Min_Value:,.0f}ì–µ ~ {row.Max_Value:,.0f}ì–µ")
            print(f"   ë³€í™”í­: {row.Range:,.0f}ì–µ")
            
            # í•´ì„
            if row.Sensitivity_Pct > 50:
                interpretation = "âš ï¸  ë§¤ìš° ë†’ì€ ì˜í–¥ - í•„ìˆ˜ ëª¨ë‹ˆí„°ë§ ëŒ€ìƒ"
            elif row.Sensitivity_Pct > 30:
                interpretation = "âš ï¸  ë†’ì€ ì˜í–¥ - ì¤‘ìš” ê´€ë¦¬ ë³€ìˆ˜"
            elif row.Sensitivity_Pct > 15:
                interpretation = "âœ“ ì¤‘ê°„ ì˜í–¥ - ì£¼ì˜ í•„ìš”"
            else:
                interpretation = "âœ“ ë‚®ì€ ì˜í–¥"
            
            print(f"   {interpretation}")
    
    # ì „ì²´ ìš”ì•½
    print(f"\n{'='*80}")
    print("ğŸ“Œ ì¢…í•© ë¶„ì„ ê²°ê³¼:")
    print(f"{'='*80}")
    
    # ëª¨ë“  ì§€í‘œì— ê³µí†µì ìœ¼ë¡œ ì˜í–¥ë ¥ í° ë³€ìˆ˜
    all_top_vars = []
    for metric in ['Financial_VaR95', 'Retail_VaR95', 'Extended_VaR95', 'System_Risk_Change']:
        metric_data = sensitivity_df[sensitivity_df['Output_Metric'] == metric]
        top3 = metric_data.nlargest(3, 'Sensitivity_Pct')
        all_top_vars.extend(top3['Variable'].tolist())
    
    from collections import Counter
    var_counts = Counter(all_top_vars)
    most_common = var_counts.most_common(3)
    
    print("\nâœ… ì „ì²´ ë¦¬ìŠ¤í¬ ì§€í‘œì— ê³µí†µì ìœ¼ë¡œ ì˜í–¥ë ¥ì´ í° ë³€ìˆ˜:")
    for i, (var, count) in enumerate(most_common, 1):
        print(f"   {i}. {var} (4ê°œ ì§€í‘œ ì¤‘ {count}ê°œì—ì„œ Top 3)")
    
    print("\nğŸ’¡ ë¦¬ìŠ¤í¬ ê´€ë¦¬ ê¶Œê³ ì‚¬í•­:")
    print("   1. ìƒìœ„ 3ê°œ ë³€ìˆ˜ë¥¼ ì§‘ì¤‘ ëª¨ë‹ˆí„°ë§")
    print("   2. í•˜ìœ„ ë³€ìˆ˜ëŠ” ê¸°ì¤€ê°’ ìœ ì§€ë¡œ ì¶©ë¶„")
    print("   3. í† ë„¤ì´ë„ ì°¨íŠ¸ì—ì„œ ë¹„ëŒ€ì¹­ì„± í™•ì¸ â†’ ë°©í–¥ì„± ìˆëŠ” ì •ì±… ìˆ˜ë¦½")


def main():
    """ë©”ì¸ ì‹¤í–‰"""
    
    start_time = time.time()
    
    print("="*80)
    print("ë¯¼ê°ë„ ë¶„ì„ (Sensitivity Analysis)")
    print("STO ë„ì… ì‹œ ë¦¬ìŠ¤í¬ ì˜í–¥ ë³€ìˆ˜ íŒŒì•…")
    print("="*80)
    
    # 1. OAT ë¯¼ê°ë„ ë¶„ì„ ì‹¤í–‰
    results, baseline = run_oat_sensitivity_analysis()
    
    # 2. ë¯¼ê°ë„ ì§€í‘œ ê³„ì‚°
    sensitivity_df = calculate_sensitivity_metrics(results, baseline)
    
    # 3. Tornado ë‹¤ì´ì–´ê·¸ë¨
    create_tornado_diagram(sensitivity_df, baseline)
    
    # 4. ë¯¼ê°ë„ ê³¡ì„ 
    create_sensitivity_curves(results, baseline)
    
    # 5. Excel ë‚´ë³´ë‚´ê¸°
    export_sensitivity_to_excel(sensitivity_df, results, baseline)
    
    # 6. ì¸ì‚¬ì´íŠ¸ ì¶œë ¥
    print_sensitivity_insights(sensitivity_df)
    
    elapsed = time.time() - start_time
    print(f"\nâ±ï¸  ì´ ì†Œìš” ì‹œê°„: {elapsed/60:.1f}ë¶„")
    
    print("\n" + "="*80)
    print("âœ… ë¯¼ê°ë„ ë¶„ì„ ì™„ë£Œ!")
    print("="*80)


if __name__ == "__main__":
    main()